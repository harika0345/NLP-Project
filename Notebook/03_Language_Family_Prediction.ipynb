{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3797253d-1dd8-4c13-9259-143cf8ec85f8",
   "metadata": {},
   "source": [
    "# Part 1 Language Family Prediction Using Neural Networks\n",
    "# This script implements two neural network approaches for predicting language families from phonological features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49198569-f0f4-4c71-8a5f-e73b212ced8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066a3270-eef4-41d5-80be-3a1a6272357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== LANGUAGE FAMILY PREDICTION ==============================\n",
      "Computation device: cpu\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Configuration and Setup\n",
    "# =====================================================================\n",
    "\n",
    "class ConfigurationSettings:\n",
    "    \"\"\"Configuration settings for the neural network models\"\"\"\n",
    "    def __init__(self):\n",
    "        # System settings\n",
    "        self.random_seed = 42\n",
    "        self.computation_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Dataset paths\n",
    "        self.phonological_features_path = 'cs_assignment3_data_1.csv'\n",
    "        self.language_families_path = 'cs_assignment3_data_2.csv'\n",
    "        \n",
    "        # Training hyperparameters\n",
    "        self.mini_batch_size = 128\n",
    "        self.gradient_learning_rate = 0.001\n",
    "        self.training_epochs = 25\n",
    "        self.early_stopping_patience = 5\n",
    "        \n",
    "        # Model architecture\n",
    "        self.feature_hidden_neurons = 256\n",
    "        self.embedding_dimension = 64\n",
    "        self.dropout_probability = 0.3\n",
    "        \n",
    "        # Results directory\n",
    "        self.results_directory = 'model_results'\n",
    "        os.makedirs(self.results_directory, exist_ok=True)\n",
    "\n",
    "# Set up configuration\n",
    "config = ConfigurationSettings()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(config.random_seed)\n",
    "np.random.seed(config.random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(config.random_seed)\n",
    "\n",
    "print(f\"{'='*30} LANGUAGE FAMILY PREDICTION {'='*30}\")\n",
    "print(f\"Computation device: {config.computation_device}\")\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d4a5ec-d230-4f3a-8d50-91ae205aa422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== LOADING AND PREPROCESSING DATA ====================\n",
      "Loading phonological features from: cs_assignment3_data_1.csv\n",
      "Loading language families from: cs_assignment3_data_2.csv\n",
      "Phonological features shape: (105488, 48)\n",
      "Language families shape: (2886, 13)\n",
      "Unique languages with family information: 2059\n",
      "Merging datasets on Glottocode...\n",
      "WARNING: 3715 samples have missing family information. Removing these samples.\n",
      "Total samples after merging: 97051\n",
      "\n",
      "Language family distribution (top 10 of 173 families):\n",
      "  1. Atlantic-Congo: 20002 sounds\n",
      "  2. Indo-European: 11555 sounds\n",
      "  3. Sino-Tibetan: 6793 sounds\n",
      "  4. Pama-Nyungan: 6210 sounds\n",
      "  5. Afro-Asiatic: 6021 sounds\n",
      "  6. Austronesian: 3673 sounds\n",
      "  7. Austroasiatic: 2788 sounds\n",
      "  8. Uralic: 2424 sounds\n",
      "  9. Mande: 2304 sounds\n",
      "  10. Dravidian: 2167 sounds\n",
      "Sounds per family - Min: 11, Max: 20002, Ratio: 1818.4x\n",
      "\n",
      "Extracting 37 phonological features\n",
      "Transforming features to binary format ('+' → 1, '-' and '0' → 0)\n",
      "Feature matrix shape: (97051, 37) (samples × features)\n",
      "\n",
      "Encoding sounds for embedding model...\n",
      "Total unique sounds: 3032\n",
      "\n",
      "Encoding language families as target classes...\n",
      "Total language families (target classes): 173\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Data Loading and Preprocessing\n",
    "# =====================================================================\n",
    "\n",
    "def load_and_preprocess_data(config):\n",
    "    \"\"\"\n",
    "    Load and preprocess the phonological features and language family datasets\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration settings object\n",
    "        \n",
    "    Returns:\n",
    "        preprocessed_data: Dictionary containing processed data\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} LOADING AND PREPROCESSING DATA {'='*20}\")\n",
    "    \n",
    "    # Load datasets\n",
    "    print(f\"Loading phonological features from: {config.phonological_features_path}\")\n",
    "    phonological_data = pd.read_csv(config.phonological_features_path, low_memory=False)\n",
    "    \n",
    "    print(f\"Loading language families from: {config.language_families_path}\")\n",
    "    language_family_data = pd.read_csv(config.language_families_path, low_memory=False)\n",
    "    \n",
    "    print(f\"Phonological features shape: {phonological_data.shape}\")\n",
    "    print(f\"Language families shape: {language_family_data.shape}\")\n",
    "    \n",
    "    # Extract unique language-family mappings\n",
    "    language_to_family_mapping = language_family_data[['Glottocode', 'Family_Name']].drop_duplicates('Glottocode')\n",
    "    print(f\"Unique languages with family information: {len(language_to_family_mapping)}\")\n",
    "    \n",
    "    # Check for languages with multiple family assignments\n",
    "    duplicate_languages = language_to_family_mapping['Glottocode'].duplicated(keep=False)\n",
    "    if duplicate_languages.any():\n",
    "        print(f\"WARNING: {duplicate_languages.sum()} languages have multiple family assignments!\")\n",
    "        print(\"Keeping first occurrence for each language\")\n",
    "        language_to_family_mapping = language_to_family_mapping.drop_duplicates('Glottocode', keep='first')\n",
    "    \n",
    "    # Merge datasets to get language family for each sound\n",
    "    print(\"Merging datasets on Glottocode...\")\n",
    "    merged_data = phonological_data.merge(\n",
    "        language_to_family_mapping, \n",
    "        on='Glottocode', \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # Check for missing values in Family_Name\n",
    "    missing_family = merged_data['Family_Name'].isna().sum()\n",
    "    if missing_family > 0:\n",
    "        print(f\"WARNING: {missing_family} samples have missing family information. Removing these samples.\")\n",
    "        merged_data = merged_data.dropna(subset=['Family_Name'])\n",
    "    \n",
    "    print(f\"Total samples after merging: {len(merged_data)}\")\n",
    "    \n",
    "    # Display language family distribution\n",
    "    family_distribution = merged_data['Family_Name'].value_counts()\n",
    "    print(f\"\\nLanguage family distribution (top 10 of {len(family_distribution)} families):\")\n",
    "    for i, (family, count) in enumerate(family_distribution.head(10).items()):\n",
    "        print(f\"  {i+1}. {family}: {count} sounds\")\n",
    "    \n",
    "    min_sounds = family_distribution.min()\n",
    "    max_sounds = family_distribution.max()\n",
    "    print(f\"Sounds per family - Min: {min_sounds}, Max: {max_sounds}, Ratio: {max_sounds/min_sounds:.1f}x\")\n",
    "    \n",
    "    # Extract and binarize phonological features\n",
    "    phonological_feature_columns = merged_data.loc[:, 'tone':'click'].columns.tolist()\n",
    "    print(f\"\\nExtracting {len(phonological_feature_columns)} phonological features\")\n",
    "    \n",
    "    # Transform features to binary as per requirements\n",
    "    print(\"Transforming features to binary format ('+' → 1, '-' and '0' → 0)\")\n",
    "    for feature_column in phonological_feature_columns:\n",
    "        merged_data[feature_column] = merged_data[feature_column].replace({'+': 1, '-': 0, '0': 0}).astype('float32')\n",
    "    \n",
    "    # Extract feature vectors\n",
    "    feature_vectors = merged_data[phonological_feature_columns].values\n",
    "    print(f\"Feature matrix shape: {feature_vectors.shape} (samples × features)\")\n",
    "    \n",
    "    # Encode each unique sound with a numerical ID for the embedding model\n",
    "    print(\"\\nEncoding sounds for embedding model...\")\n",
    "    merged_data['sound_id'] = pd.Categorical(merged_data['Phoneme']).codes\n",
    "    sound_ids = merged_data['sound_id'].values\n",
    "    unique_sound_count = merged_data['sound_id'].nunique()\n",
    "    print(f\"Total unique sounds: {unique_sound_count}\")\n",
    "    \n",
    "    # Encode language families as target classes\n",
    "    print(\"\\nEncoding language families as target classes...\")\n",
    "    merged_data['family_class_id'] = pd.Categorical(merged_data['Family_Name']).codes\n",
    "    target_classes = merged_data['family_class_id'].values\n",
    "    class_count = merged_data['family_class_id'].nunique()\n",
    "    print(f\"Total language families (target classes): {class_count}\")\n",
    "    \n",
    "    # Create mapping dictionaries for interpretation\n",
    "    sound_to_id = {sound: id for id, sound in enumerate(merged_data['Phoneme'].unique())}\n",
    "    id_to_sound = {id: sound for sound, id in sound_to_id.items()}\n",
    "    \n",
    "    family_to_id = {family: id for id, family in enumerate(merged_data['Family_Name'].unique())}\n",
    "    id_to_family = {id: family for family, id in family_to_id.items()}\n",
    "    \n",
    "    # Store processed data in dictionary\n",
    "    preprocessed_data = {\n",
    "        'feature_vectors': feature_vectors,\n",
    "        'sound_ids': sound_ids.reshape(-1, 1),  # Reshape for embedding input\n",
    "        'target_classes': target_classes,\n",
    "        'unique_sound_count': unique_sound_count,\n",
    "        'class_count': class_count,\n",
    "        'feature_columns': phonological_feature_columns,\n",
    "        'sound_to_id': sound_to_id,\n",
    "        'id_to_sound': id_to_sound,\n",
    "        'family_to_id': family_to_id,\n",
    "        'id_to_family': id_to_family,\n",
    "        'merged_data': merged_data\n",
    "    }\n",
    "    \n",
    "    return preprocessed_data\n",
    "\n",
    "# Load and preprocess data\n",
    "preprocessed_data = load_and_preprocess_data(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e5a76b-4ba6-4cd4-8977-a69d50839f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== PREPARING DATASETS AND DATALOADERS ====================\n",
      "Creating stratified train/test split with test_size=0.2, random_state=42\n",
      "Training set: 77640 samples\n",
      "Testing set: 19411 samples\n",
      "Converting data to PyTorch tensors...\n",
      "Creating TensorDatasets...\n",
      "Creating DataLoaders with batch_size=128...\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Data Splitting and DataLoader Creation\n",
    "# =====================================================================\n",
    "\n",
    "def prepare_data_loaders(preprocessed_data, config):\n",
    "    \"\"\"\n",
    "    Prepare training and testing datasets and dataloaders\n",
    "    \n",
    "    Args:\n",
    "        preprocessed_data: Dictionary containing processed data\n",
    "        config: Configuration settings object\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing dataloaders and dataset info\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} PREPARING DATASETS AND DATALOADERS {'='*20}\")\n",
    "    \n",
    "    # Extract data from dictionary\n",
    "    feature_vectors = preprocessed_data['feature_vectors']\n",
    "    sound_ids = preprocessed_data['sound_ids']\n",
    "    target_classes = preprocessed_data['target_classes']\n",
    "    \n",
    "    # Create stratified train/test split\n",
    "    print(f\"Creating stratified train/test split with test_size=0.2, random_state={config.random_seed}\")\n",
    "    features_train, features_test, sounds_train, sounds_test, targets_train, targets_test = train_test_split(\n",
    "        feature_vectors, \n",
    "        sound_ids, \n",
    "        target_classes,\n",
    "        test_size=0.2, \n",
    "        random_state=config.random_seed, \n",
    "        stratify=target_classes\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {len(features_train)} samples\")\n",
    "    print(f\"Testing set: {len(features_test)} samples\")\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    print(\"Converting data to PyTorch tensors...\")\n",
    "    # For Model 1 (Feature vectors)\n",
    "    features_train_tensor = torch.FloatTensor(features_train)\n",
    "    features_test_tensor = torch.FloatTensor(features_test)\n",
    "    \n",
    "    # For Model 2 (Embeddings)\n",
    "    sounds_train_tensor = torch.LongTensor(sounds_train)\n",
    "    sounds_test_tensor = torch.LongTensor(sounds_test)\n",
    "    \n",
    "    # Target tensors (same for both models)\n",
    "    targets_train_tensor = torch.LongTensor(targets_train)\n",
    "    targets_test_tensor = torch.LongTensor(targets_test)\n",
    "    \n",
    "    # Create TensorDatasets\n",
    "    print(\"Creating TensorDatasets...\")\n",
    "    feature_train_dataset = TensorDataset(features_train_tensor, targets_train_tensor)\n",
    "    feature_test_dataset = TensorDataset(features_test_tensor, targets_test_tensor)\n",
    "    \n",
    "    sound_train_dataset = TensorDataset(sounds_train_tensor, targets_train_tensor)\n",
    "    sound_test_dataset = TensorDataset(sounds_test_tensor, targets_test_tensor)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    print(f\"Creating DataLoaders with batch_size={config.mini_batch_size}...\")\n",
    "    feature_train_loader = DataLoader(\n",
    "        feature_train_dataset, \n",
    "        batch_size=config.mini_batch_size, \n",
    "        shuffle=True,\n",
    "        pin_memory=True if config.computation_device.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    feature_test_loader = DataLoader(\n",
    "        feature_test_dataset, \n",
    "        batch_size=config.mini_batch_size, \n",
    "        shuffle=False,\n",
    "        pin_memory=True if config.computation_device.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    sound_train_loader = DataLoader(\n",
    "        sound_train_dataset, \n",
    "        batch_size=config.mini_batch_size, \n",
    "        shuffle=True,\n",
    "        pin_memory=True if config.computation_device.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    sound_test_loader = DataLoader(\n",
    "        sound_test_dataset, \n",
    "        batch_size=config.mini_batch_size, \n",
    "        shuffle=False,\n",
    "        pin_memory=True if config.computation_device.type == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    data_loaders = {\n",
    "        'feature_train_loader': feature_train_loader,\n",
    "        'feature_test_loader': feature_test_loader,\n",
    "        'sound_train_loader': sound_train_loader,\n",
    "        'sound_test_loader': sound_test_loader,\n",
    "        'features_train': features_train,\n",
    "        'features_test': features_test,\n",
    "        'sounds_train': sounds_train,\n",
    "        'sounds_test': sounds_test,\n",
    "        'targets_train': targets_train,\n",
    "        'targets_test': targets_test\n",
    "    }\n",
    "    \n",
    "    return data_loaders\n",
    "\n",
    "# Prepare data loaders\n",
    "data_loaders = prepare_data_loaders(preprocessed_data, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374271c6-a2ac-41ae-b1dc-691ad3061dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# Model Definitions\n",
    "# =====================================================================\n",
    "\n",
    "class PhonologicalFeatureModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model that takes phonological feature vectors as input\n",
    "    and predicts language family.\n",
    "    \n",
    "    Model 1 as per requirements: Uses feature vectors\n",
    "    \"\"\"\n",
    "    def __init__(self, input_features, hidden_size, num_classes, dropout_prob=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features: Number of input features (phonological features)\n",
    "            hidden_size: Size of hidden layer\n",
    "            num_classes: Number of output classes (language families)\n",
    "            dropout_prob: Dropout probability for regularization\n",
    "        \"\"\"\n",
    "        super(PhonologicalFeatureModel, self).__init__()\n",
    "        \n",
    "        self.model_layers = nn.Sequential(\n",
    "            # Input layer\n",
    "            nn.Linear(input_features, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features_batch):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        return self.model_layers(features_batch)\n",
    "\n",
    "class PhonemeEmbeddingModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network model that uses sound embeddings as input\n",
    "    and predicts language family.\n",
    "    \n",
    "    Model 2 as per requirements: Uses embeddings instead of feature vectors\n",
    "    \"\"\"\n",
    "    def __init__(self, vocabulary_size, embedding_dim, hidden_size, num_classes, dropout_prob=0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocabulary_size: Number of unique sounds in the dataset\n",
    "            embedding_dim: Size of the embedding vectors\n",
    "            hidden_size: Size of hidden layer\n",
    "            num_classes: Number of output classes (language families)\n",
    "            dropout_prob: Dropout probability for regularization\n",
    "        \"\"\"\n",
    "        super(PhonemeEmbeddingModel, self).__init__()\n",
    "        \n",
    "        # Embedding layer maps each sound ID to a dense vector\n",
    "        self.embedding_layer = nn.Embedding(vocabulary_size, embedding_dim)\n",
    "        \n",
    "        # Neural network layers after embedding\n",
    "        self.model_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            \n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, sound_ids_batch):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        # Get embeddings and remove extra dimension\n",
    "        embedded_sounds = self.embedding_layer(sound_ids_batch).squeeze(1)\n",
    "        \n",
    "        # Pass through the rest of the network\n",
    "        return self.model_layers(embedded_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318ca619-3593-4ca1-ae30-c23592c668d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================================\n",
    "# Model Training and Evaluation\n",
    "# =====================================================================\n",
    "\n",
    "def train_model(model, data_loader, optimizer, criterion, device, epoch, total_epochs):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        data_loader: DataLoader with training data\n",
    "        optimizer: Optimizer for weight updates\n",
    "        criterion: Loss function\n",
    "        device: Device to run training on (CPU/GPU)\n",
    "        epoch: Current epoch number\n",
    "        total_epochs: Total number of epochs\n",
    "        \n",
    "    Returns:\n",
    "        average_loss: Average loss over the epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch}/{total_epochs} [Train]\")\n",
    "    \n",
    "    for inputs, targets in progress_bar:\n",
    "        # Move tensors to the configured device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += targets.size(0)\n",
    "        correct_predictions += (predicted == targets).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix(\n",
    "            loss=f\"{loss.item():.4f}\", \n",
    "            accuracy=f\"{100 * correct_predictions / total_samples:.2f}%\"\n",
    "        )\n",
    "    \n",
    "    average_loss = running_loss / len(data_loader.dataset)\n",
    "    accuracy = 100 * correct_predictions / total_samples\n",
    "    \n",
    "    return average_loss, accuracy\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device, id_to_family=None):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        data_loader: DataLoader with test data\n",
    "        criterion: Loss function\n",
    "        device: Device to run evaluation on (CPU/GPU)\n",
    "        id_to_family: Dictionary mapping class IDs to family names\n",
    "        \n",
    "    Returns:\n",
    "        metrics: Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # Disable gradient calculation for evaluation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            # Move tensors to the configured device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Update statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store predictions and targets for metrics calculation\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    mcc = matthews_corrcoef(all_targets, all_predictions)\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    class_report = classification_report(\n",
    "        all_targets, \n",
    "        all_predictions, \n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Convert numeric indices to family names if provided\n",
    "    if id_to_family:\n",
    "        class_report_named = {}\n",
    "        for class_id, metrics in class_report.items():\n",
    "            if class_id in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                class_report_named[class_id] = metrics\n",
    "            else:\n",
    "                family_name = id_to_family[int(class_id)]\n",
    "                class_report_named[family_name] = metrics\n",
    "        class_report = class_report_named\n",
    "    \n",
    "    # Calculate confusion matrix (take a sample if too many classes)\n",
    "    num_classes = len(set(all_targets))\n",
    "    if num_classes <= 20:  # Only create confusion matrix for reasonable number of classes\n",
    "        conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "    else:\n",
    "        conf_matrix = None\n",
    "    \n",
    "    # Average loss\n",
    "    average_loss = running_loss / len(data_loader.dataset)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': average_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'mcc': mcc,\n",
    "        'classification_report': class_report,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate(model_name, model, train_loader, test_loader, config, id_to_family=None):\n",
    "    \"\"\"\n",
    "    Complete training and evaluation pipeline for a model\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model for logging\n",
    "        model: PyTorch model to train\n",
    "        train_loader: DataLoader with training data\n",
    "        test_loader: DataLoader with test data\n",
    "        config: Configuration settings\n",
    "        id_to_family: Dictionary mapping class IDs to family names\n",
    "        \n",
    "    Returns:\n",
    "        metrics: Dictionary containing evaluation metrics and training history\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} TRAINING {model_name} {'='*20}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(config.computation_device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=config.gradient_learning_rate\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_accuracy': []\n",
    "    }\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, config.training_epochs + 1):\n",
    "        # Train for one epoch\n",
    "        epoch_loss, epoch_accuracy = train_model(\n",
    "            model=model,\n",
    "            data_loader=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            device=config.computation_device,\n",
    "            epoch=epoch,\n",
    "            total_epochs=config.training_epochs\n",
    "        )\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_accuracy'].append(epoch_accuracy)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch}/{config.training_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= config.early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch} - No improvement for {config.early_stopping_patience} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Restore best model state if early stopping occurred\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"\\n{'='*20} EVALUATING {model_name} {'='*20}\")\n",
    "    evaluation_metrics = evaluate_model(\n",
    "        model=model,\n",
    "        data_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=config.computation_device,\n",
    "        id_to_family=id_to_family\n",
    "    )\n",
    "    \n",
    "    # Combine history and evaluation metrics\n",
    "    metrics = {\n",
    "        'history': history,\n",
    "        **evaluation_metrics\n",
    "    }\n",
    "    \n",
    "    # Print evaluation results\n",
    "    print(f\"\\n{model_name} Evaluation Results:\")\n",
    "    print(f\"  Accuracy: {evaluation_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  MCC: {evaluation_metrics['mcc']:.4f}\")\n",
    "    print(f\"  Loss: {evaluation_metrics['loss']:.4f}\")\n",
    "    \n",
    "    # Print top 5 and bottom 5 performing language families\n",
    "    if id_to_family:\n",
    "        class_report = evaluation_metrics['classification_report']\n",
    "        family_f1_scores = {}\n",
    "        \n",
    "        for class_name, metrics in class_report.items():\n",
    "            if class_name not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                family_f1_scores[class_name] = metrics['f1-score']\n",
    "        \n",
    "        # Sort by F1 score\n",
    "        sorted_families = sorted(family_f1_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"\\n  Top 5 performing language families (F1 score):\")\n",
    "        for i, (family, f1) in enumerate(sorted_families[:5]):\n",
    "            print(f\"    {i+1}. {family}: {f1:.4f}\")\n",
    "        \n",
    "        print(\"\\n  Bottom 5 performing language families (F1 score):\")\n",
    "        for i, (family, f1) in enumerate(sorted_families[-5:]):\n",
    "            print(f\"    {i+1}. {family}: {f1:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea04626-4469-421e-8c93-a96d974f7723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1: Phonological Feature Model\n",
      "PhonologicalFeatureModel(\n",
      "  (model_layers): Sequential(\n",
      "    (0): Linear(in_features=37, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=173, bias=True)\n",
      "  )\n",
      ")\n",
      "Total parameters: 54701\n",
      "\n",
      "Model 2: Phoneme Embedding Model\n",
      "PhonemeEmbeddingModel(\n",
      "  (embedding_layer): Embedding(3033, 64)\n",
      "  (model_layers): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=173, bias=True)\n",
      "  )\n",
      ")\n",
      "Total parameters: 255725\n",
      "\n",
      "==================== TRAINING Model 1 (Phonological Feature Model) ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:07<00:00, 77.14it/s, accuracy=23.19%, loss=3.0602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Loss: 3.3622, Accuracy: 23.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:07<00:00, 77.62it/s, accuracy=25.45%, loss=3.1400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 - Loss: 3.2044, Accuracy: 25.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:07<00:00, 76.43it/s, accuracy=25.86%, loss=3.4403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 - Loss: 3.1634, Accuracy: 25.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:07<00:00, 77.86it/s, accuracy=26.07%, loss=2.7988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 - Loss: 3.1439, Accuracy: 26.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:07<00:00, 75.90it/s, accuracy=26.28%, loss=3.5029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 - Loss: 3.1303, Accuracy: 26.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:07<00:00, 78.36it/s, accuracy=26.47%, loss=3.2064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 - Loss: 3.1190, Accuracy: 26.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:08<00:00, 74.63it/s, accuracy=26.51%, loss=3.2525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 - Loss: 3.1100, Accuracy: 26.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:07<00:00, 78.12it/s, accuracy=26.62%, loss=2.9615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 - Loss: 3.1045, Accuracy: 26.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:07<00:00, 77.79it/s, accuracy=26.63%, loss=3.1863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 - Loss: 3.0988, Accuracy: 26.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 78.19it/s, accuracy=26.69%, loss=3.3027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 - Loss: 3.0926, Accuracy: 26.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 80.18it/s, accuracy=26.83%, loss=2.9497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 - Loss: 3.0888, Accuracy: 26.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:06<00:00, 86.90it/s, accuracy=26.84%, loss=3.3771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 - Loss: 3.0847, Accuracy: 26.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 77.80it/s, accuracy=26.84%, loss=3.4607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 - Loss: 3.0808, Accuracy: 26.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 76.87it/s, accuracy=26.82%, loss=3.4685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 - Loss: 3.0775, Accuracy: 26.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 79.35it/s, accuracy=26.88%, loss=2.5757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 - Loss: 3.0736, Accuracy: 26.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 79.13it/s, accuracy=26.99%, loss=3.3477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 - Loss: 3.0721, Accuracy: 26.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 76.74it/s, accuracy=26.84%, loss=2.9809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 - Loss: 3.0680, Accuracy: 26.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 80.72it/s, accuracy=27.00%, loss=3.2541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 - Loss: 3.0657, Accuracy: 27.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 80.37it/s, accuracy=27.03%, loss=3.2996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 - Loss: 3.0618, Accuracy: 27.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 77.75it/s, accuracy=27.06%, loss=3.3921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 - Loss: 3.0599, Accuracy: 27.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:08<00:00, 75.53it/s, accuracy=27.03%, loss=2.6460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 - Loss: 3.0583, Accuracy: 27.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 78.08it/s, accuracy=27.08%, loss=2.8932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 - Loss: 3.0566, Accuracy: 27.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 78.73it/s, accuracy=27.22%, loss=3.2032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 - Loss: 3.0544, Accuracy: 27.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 78.79it/s, accuracy=27.12%, loss=3.1393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 - Loss: 3.0526, Accuracy: 27.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:07<00:00, 78.71it/s, accuracy=27.11%, loss=2.7166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 - Loss: 3.0502, Accuracy: 27.11%\n",
      "\n",
      "==================== EVALUATING Model 1 (Phonological Feature Model) ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████| 152/152 [00:00<00:00, 216.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1 (Phonological Feature Model) Evaluation Results:\n",
      "  Accuracy: 0.2723\n",
      "  MCC: 0.1570\n",
      "  Loss: 3.0844\n",
      "\n",
      "  Top 5 performing language families (F1 score):\n",
      "    1. Gumuz: 0.4651\n",
      "    2. Baining: 0.4255\n",
      "    3. Tai-Kadai: 0.3990\n",
      "    4. Chocoan: 0.3857\n",
      "    5. Central Sudanic: 0.2561\n",
      "\n",
      "  Bottom 5 performing language families (F1 score):\n",
      "    1. Marrku-Wurrugu: 0.0000\n",
      "    2. Jarrakan: 0.0000\n",
      "    3. Mirndi: 0.0000\n",
      "    4. Tangkic: 0.0000\n",
      "    5. Yangmanic: 0.0000\n",
      "\n",
      "==================== TRAINING Model 2 (Phoneme Embedding Model) ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:09<00:00, 66.33it/s, accuracy=22.72%, loss=3.3166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 - Loss: 3.4262, Accuracy: 22.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:09<00:00, 65.40it/s, accuracy=25.33%, loss=2.9951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25 - Loss: 3.2509, Accuracy: 25.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:09<00:00, 65.88it/s, accuracy=26.08%, loss=3.1626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25 - Loss: 3.1918, Accuracy: 26.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:08<00:00, 68.70it/s, accuracy=26.61%, loss=3.0324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25 - Loss: 3.1526, Accuracy: 26.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:09<00:00, 63.46it/s, accuracy=26.92%, loss=3.3784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25 - Loss: 3.1264, Accuracy: 26.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:09<00:00, 63.09it/s, accuracy=27.39%, loss=3.3053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25 - Loss: 3.1044, Accuracy: 27.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:09<00:00, 63.37it/s, accuracy=27.63%, loss=2.9480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25 - Loss: 3.0837, Accuracy: 27.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:09<00:00, 62.58it/s, accuracy=27.79%, loss=2.8564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25 - Loss: 3.0679, Accuracy: 27.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 [Train]: 100%|█████████████████████████████████████| 607/607 [00:09<00:00, 62.31it/s, accuracy=27.93%, loss=3.1460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25 - Loss: 3.0531, Accuracy: 27.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 61.83it/s, accuracy=28.19%, loss=2.8380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25 - Loss: 3.0399, Accuracy: 28.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 61.62it/s, accuracy=28.26%, loss=3.1906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25 - Loss: 3.0303, Accuracy: 28.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 63.18it/s, accuracy=28.45%, loss=2.8238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25 - Loss: 3.0193, Accuracy: 28.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 63.21it/s, accuracy=28.61%, loss=3.4549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25 - Loss: 3.0080, Accuracy: 28.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 63.17it/s, accuracy=28.64%, loss=3.2057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25 - Loss: 2.9995, Accuracy: 28.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 63.56it/s, accuracy=28.77%, loss=2.9287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25 - Loss: 2.9921, Accuracy: 28.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 63.73it/s, accuracy=29.04%, loss=2.6620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25 - Loss: 2.9813, Accuracy: 29.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 63.43it/s, accuracy=28.97%, loss=3.0640]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25 - Loss: 2.9749, Accuracy: 28.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 63.70it/s, accuracy=29.07%, loss=2.8634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25 - Loss: 2.9709, Accuracy: 29.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 62.75it/s, accuracy=29.21%, loss=3.1435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25 - Loss: 2.9630, Accuracy: 29.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 63.91it/s, accuracy=29.20%, loss=2.9633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25 - Loss: 2.9586, Accuracy: 29.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 62.88it/s, accuracy=29.40%, loss=3.1370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25 - Loss: 2.9533, Accuracy: 29.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 62.33it/s, accuracy=29.41%, loss=2.9449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25 - Loss: 2.9478, Accuracy: 29.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 62.72it/s, accuracy=29.52%, loss=2.9676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25 - Loss: 2.9431, Accuracy: 29.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 62.66it/s, accuracy=29.55%, loss=2.7222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25 - Loss: 2.9369, Accuracy: 29.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 [Train]: 100%|████████████████████████████████████| 607/607 [00:09<00:00, 62.38it/s, accuracy=29.61%, loss=2.8260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25 - Loss: 2.9340, Accuracy: 29.61%\n",
      "\n",
      "==================== EVALUATING Model 2 (Phoneme Embedding Model) ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████| 152/152 [00:00<00:00, 231.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 2 (Phoneme Embedding Model) Evaluation Results:\n",
      "  Accuracy: 0.2799\n",
      "  MCC: 0.1668\n",
      "  Loss: 3.1341\n",
      "\n",
      "  Top 5 performing language families (F1 score):\n",
      "    1. Chocoan: 0.4519\n",
      "    2. Tai-Kadai: 0.4073\n",
      "    3. Central Sudanic: 0.2922\n",
      "    4. Timor-Alor-Pantar: 0.2574\n",
      "    5. Kiwaian: 0.1865\n",
      "\n",
      "  Bottom 5 performing language families (F1 score):\n",
      "    1. Marrku-Wurrugu: 0.0000\n",
      "    2. Jarrakan: 0.0000\n",
      "    3. Mirndi: 0.0000\n",
      "    4. Tangkic: 0.0000\n",
      "    5. Yangmanic: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Initialize and Train Models\n",
    "# =====================================================================\n",
    "\n",
    "# Initialize Model 1: Phonological Feature Model\n",
    "feature_model = PhonologicalFeatureModel(\n",
    "    input_features=preprocessed_data['feature_vectors'].shape[1],\n",
    "    hidden_size=config.feature_hidden_neurons,\n",
    "    num_classes=preprocessed_data['class_count'],\n",
    "    dropout_prob=config.dropout_probability\n",
    ")\n",
    "\n",
    "# Initialize Model 2: Phoneme Embedding Model\n",
    "embedding_model = PhonemeEmbeddingModel(\n",
    "    vocabulary_size=preprocessed_data['unique_sound_count'] + 1,  # +1 for padding\n",
    "    embedding_dim=config.embedding_dimension,\n",
    "    hidden_size=config.feature_hidden_neurons,\n",
    "    num_classes=preprocessed_data['class_count'],\n",
    "    dropout_prob=config.dropout_probability\n",
    ")\n",
    "\n",
    "# Display model architectures\n",
    "print(\"\\nModel 1: Phonological Feature Model\")\n",
    "print(feature_model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in feature_model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "print(\"\\nModel 2: Phoneme Embedding Model\")\n",
    "print(embedding_model)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in embedding_model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "# Train and evaluate Model 1\n",
    "feature_model_metrics = train_and_evaluate(\n",
    "    model_name=\"Model 1 (Phonological Feature Model)\",\n",
    "    model=feature_model,\n",
    "    train_loader=data_loaders['feature_train_loader'],\n",
    "    test_loader=data_loaders['feature_test_loader'],\n",
    "    config=config,\n",
    "    id_to_family=preprocessed_data['id_to_family']\n",
    ")\n",
    "\n",
    "# Train and evaluate Model 2\n",
    "embedding_model_metrics = train_and_evaluate(\n",
    "    model_name=\"Model 2 (Phoneme Embedding Model)\",\n",
    "    model=embedding_model,\n",
    "    train_loader=data_loaders['sound_train_loader'],\n",
    "    test_loader=data_loaders['sound_test_loader'],\n",
    "    config=config,\n",
    "    id_to_family=preprocessed_data['id_to_family']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd685315-8725-4b12-834c-1a4ba43b9004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
